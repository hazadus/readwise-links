# Ğ¡ÑÑ‹Ğ»ĞºĞ¸

- Ğ’ÑĞµĞ³Ğ¾ ÑÑÑ‹Ğ»Ğ¾Ğº: 83

## Ğ¡ÑÑ‹Ğ»ĞºĞ¸

- [I really donâ€™t like ChatGPTâ€™s new memory feature](https://simonwillison.net/2025/May/21/chatgpt-new-memory/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 2161 ğŸ”– #llm ğŸ—“ï¸ 2025-05-22
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author expresses frustration with ChatGPT's new memory feature, which allows the AI to reference past conversations for personalized responses. They highlight concerns about losing control over what information is remembered and the potential impact on future interactions. The author wishes for a more customizable memory option that allows users to manage which past chats are considered in ongoing conversations.
- [Practical AI techniques for daily engineering work](https://seangoedecke.com/practical-ai-techniques/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1120 ğŸ”– #llm ğŸ—“ï¸ 2025-05-21
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author shares practical AI techniques for experienced software engineers, focusing on how to use AI for second opinions and quick debugging scripts. By leveraging AI's strengths, engineers can simplify complex code or generate short programs to automate debugging tasks. Additional tips include using AI to find evidence for arguments and to help with unfamiliar technical tasks, but these are secondary to the main techniques.
- [After months of coding with LLMs, I'm going back to using my brain](https://albertofortin.com/writing/coding-with-ai) ğŸ‘¤ Alberto ğŸ’¬ 1793 ğŸ”– #llm ğŸ—“ï¸ 2025-05-21
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Alberto found that while large language models (LLMs) can help with coding, they often produce messy and inconsistent results. After facing frustration with the code generated by AI, he decided to rely more on his own skills and knowledge, using LLMs only for minor tasks. He believes that while AI tools can be useful, they may lead to confusion and a decline in critical thinking for those without coding experience.
- [First Steps With LangChain](https://realpython.com/courses/first-steps-langchain/) ğŸ‘¤ Real Python ğŸ’¬ 129 ğŸ”– #llm, #python, #langchain ğŸ—“ï¸ 2025-05-21
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** This course teaches you how to use LangChain to build applications powered by large language models (LLMs). You'll learn to create reusable prompts, extend chains, and debug your applications. The course includes videos, transcripts, resources, and a certificate of completion.
- [LangGraph Complete Course for Beginners â€“ Complex AI Agents](https://www.youtube.com/watch?v=jGg_1h0qzaM) ğŸ‘¤ freeCodeCamp.org ğŸ”– #llm, #agents, #langgraph ğŸ—“ï¸ 2025-05-21
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Welcome to this video course on LangGraph, the powerful Python library for building advanced conversational AI workflows. In this course, Vaibhav Mehra will teach you how to design, implement, and manage complex dialogue systems using a graph-based approach. By the end, you'll be equipped to build robust, scalable conversational applications that leverage the full potential of large language models.

Code: https://github.com/Vaibhav807/LangGraph-Course

Vaibhav Mehra on LinkedIn: https://www.linkedin.com/in/vaibhav-mehra-main/

â¤ï¸ Support for this channel comes from our friends at Scrimba â€“ the coding platform that's reinvented interactive learning: https://scrimba.com/freecodecamp

â­ï¸ Contents â­ï¸
âŒ¨ï¸ (0:00:00) Introduction
âŒ¨ï¸ (0:26:58) Type Annotations
âŒ¨ï¸ (0:34:09) Elements
âŒ¨ï¸ (0:44:13) Agent 1 Intro
âŒ¨ï¸ (0:46:42) Agent 1 Code
âŒ¨ï¸ (0:57:56) Agent 1 Exercise
âŒ¨ï¸ (0:58:41) Agent 2 Intro
âŒ¨ï¸ (0:59:36) Agent 2 Code
âŒ¨ï¸ (1:09:01) Agent 2 Exercise
âŒ¨ï¸ (1:10:03) Agent 3 Intro
âŒ¨ï¸ (1:10:52) Agent 3 Code
âŒ¨ï¸ (1:19:38) Agent 3 Exercise
âŒ¨ï¸ (1:21:10) Agent 4 Intro
âŒ¨ï¸ (1:22:11) Agent 4 Code
âŒ¨ï¸ (1:38:43) Agent 4 Exercise
âŒ¨ï¸ (1:39:48) Agent 5 Intro
âŒ¨ï¸ (1:41:19) Agent 5 Code
âŒ¨ï¸ (1:54:53) Agent 5 Exercise
âŒ¨ï¸ (1:56:35) AI Agent 1 Intro
âŒ¨ï¸ (1:58:23) AI Agent 1 Code
âŒ¨ï¸ (2:08:28) AI Agent 2 Intro
âŒ¨ï¸ (2:09:32) AI Agent 2 Code
âŒ¨ï¸ (2:28:54) AI Agent 3 Intro
âŒ¨ï¸ (2:30:34) AI Agent 3 Prerequisite
âŒ¨ï¸ (2:38:02) AI Agent 3 Code
âŒ¨ï¸ (2:54:20) AI Agent 4 Intro
âŒ¨ï¸ (2:56:33) AI Agent 4 Code
âŒ¨ï¸ (3:17:43) RAG Agent Intro
âŒ¨ï¸ (3:18:35) RAG Agent Code
âŒ¨ï¸ (3:31:49) RAG Agent Testing
âŒ¨ï¸ (3:34:38) Course Outro

ğŸ‰ Thanks to our Champion and Sponsor supporters:
ğŸ‘¾ Drake Milly
ğŸ‘¾ Ulises Moralez
ğŸ‘¾ Goddard Tan
ğŸ‘¾ David MG
ğŸ‘¾ Matthew Springman
ğŸ‘¾ Claudio
ğŸ‘¾ Oscar R.
ğŸ‘¾ jedi-or-sith
ğŸ‘¾ Nattira Maneerat
ğŸ‘¾ Justin Hual

--

Learn to code for free and get a developer job: https://www.freecodecamp.org

Read hundreds of articles on programming: https://freecodecamp.org/news
- [Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹Â â€” Ğ²Ğ¾Ñ‚ Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ. ĞŸĞ¸ÑˆĞµĞ¼ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ½Ğ° Python, LangChain Ğ¸ GigaChat](https://youtube.com/watch?v=KFgwXXWT7sQ&si=9c1fWb9ps_90PRff) ğŸ‘¤ Ğ”Ğ¸Ğ´Ğ¶Ğ¸Ñ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹! ğŸ”– #llm, #agents, #langchain, #inspiration ğŸ—“ï¸ 2025-05-19
    > **Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ°:** Ğ˜Ğ½Ñ‚ĞµÑ€ĞµÑĞ½Ñ‹Ğ¹ Ğ¸ Ğ²Ğ´Ğ¾Ñ…Ğ½Ğ¾Ğ²Ğ»ÑÑÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸.
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¸Ğ·Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸, Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑÑ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡. Ğ’ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ€Ğ°ÑÑĞ¼Ğ°Ñ‚Ñ€Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ˜Ğ˜-Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ½Ğ° Python Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ LangChain Ğ¸ GigaChat Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ². Ğ­Ñ‚Ğ¾ Ğ¾Ğ±Ğ»ĞµĞ³Ñ‡Ğ°ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ, Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑÑ Ğ¸Ğ·Ğ²Ğ»ĞµĞºĞ°Ñ‚ÑŒ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ².
- [Diffusion models explained simply](https://seangoedecke.com/diffusion-models-explained/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1775 ğŸ”– #llm ğŸ—“ï¸ 2025-05-19
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Diffusion models generate images by starting with pure noise and gradually removing it based on the input caption. They differ from transformer models by working with images directly rather than sequences of tokens, allowing for flexibility in image quality and structure. While image and video diffusion models are well-developed, text-based diffusion models face unique challenges in adding and removing noise.
- [For many, patience is the killer LLM feature](https://seangoedecke.com/patience-too-cheap-to-meter/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 800 ğŸ”– #llm ğŸ—“ï¸ 2025-05-18
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Many people prefer using ChatGPT because it offers superhuman patience and is always available for support. This makes it useful for tasks like therapy, where users can seek advice without fear of judgment. While language models may not replace professional therapists, their constant availability and understanding nature provide significant value to users.
- [Building software on top of Large Language Models](https://simonwillison.net/2025/May/15/building-on-llms/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 2330 ğŸ”– #llm ğŸ—“ï¸ 2025-05-16
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Simon Willison held a three-hour workshop at PyCon US on building software using Large Language Models (LLMs). The workshop covered topics like setting up LLMs, prompting techniques, and creating a text to SQL tool. Participants learned about the economic value of structured data extraction and the importance of tool usage and security in LLM applications.
- [They expect us to keep changing](https://benv.ca/blog/posts/they-expect-us-to-keep-changing) ğŸ‘¤ benv.ca ğŸ’¬ 1358 ğŸ”– #llm, #learning ğŸ—“ï¸ 2025-05-15
    > **Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ°:** Ğ Ğ°Ğ·Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ‚ĞµĞ¼Ñƒ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞµ, ÑĞ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¿Ğ¾ÑĞ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ LLM. Ğ’Ñ‹Ğ²Ğ¾Ğ´ - Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ±Ñ‹Ğ»Ğ¸ Ğ¸ Ğ±ÑƒĞ´ÑƒÑ‚, ÑÑ‚Ğ¾ Ğ½Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ. ĞÑƒĞ¶Ğ½Ğ¾ Ğ°Ğ´Ğ°Ğ¿Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ. 
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Software engineers are feeling anxious as AI rapidly changes the development landscape, forcing many to learn new skills. This change is not new; developers have faced similar challenges before and must adapt to stay relevant. The author reflects on a past encounter with a worried programmer, highlighting that change and anxiety are part of the tech industryâ€™s history.
- [What does vibe coding mean?](https://www.merriam-webster.com/slang/vibe-coding) ğŸ‘¤ merriam-webster.com ğŸ’¬ 330 ğŸ”– #llm ğŸ—“ï¸ 2025-05-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Vibe coding is a new way of creating code by simply telling an AI what you want, without needing to understand the underlying code. This method may lead to bugs and glitches, which some users accept, especially for personal projects. The term was popularized in early 2025 by Andrej Karpathy and may evolve in meaning as it becomes more widely used.
- [Why can't language models come up with new ideas?](https://seangoedecke.com/why-cant-ais-have-new-ideas/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1192 ğŸ”– #llm ğŸ—“ï¸ 2025-05-12
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Language models struggle to generate new ideas because they rely on existing training data, similar to how humans combine past experiences to create novel concepts. While there are instances where language models produce new suggestions, these often lack the depth and innovation seen in human creativity. Improving their ability to generate meaningful ideas may require better engineering and scaffolding techniques.
- [Basic Claude Code](https://harper.blog/2025/05/08/basic-claude-code/) ğŸ‘¤ Harper Reed <harper@modest.com> ğŸ’¬ 1490 ğŸ”– #llm, #development, #inspiration ğŸ—“ï¸ 2025-05-10
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author discusses the benefits of using Claude Code for coding workflows, highlighting its power and effectiveness. They emphasize the importance of practices like test-driven development and linting to improve code quality. The author also shares their team's positive experiences and encourages readers to share their own workflows.
- [How to Build Your Own Local AI: Create Free RAG and AI Agents with Qwen 3 and Ollama](https://www.freecodecamp.org/news/build-a-local-ai/) ğŸ‘¤ freeCodeCamp.org ğŸ’¬ 4576 ğŸ”– #llm, #agents ğŸ—“ï¸ 2025-05-08
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The article explains how to build a local AI using Qwen 3, an open-source language model from Alibaba, and the Ollama tool, which simplifies running these models. It provides a step-by-step guide for setting up a local AI environment, creating a Retrieval-Augmented Generation (RAG) system, and developing basic AI agents. By following this tutorial, users can leverage powerful AI tools on their own hardware for free.
- [I don't care about your magic prompts](https://seangoedecke.com/magic-prompts/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 761 ğŸ”– #llm ğŸ—“ï¸ 2025-05-07
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Many tech influencers promote "magic prompts" that claim to unlock superhuman abilities with language models, but this approach is misleading. Instead of focusing on perfect prompts, it's more important to understand what language models can do and how to provide them with the right context for effective use. Building skills in using AI involves experimenting with different tasks and learning from the model's strengths and weaknesses, rather than relying on a library of prompts.
- [sycophancy is the first LLM â€œdark patternâ€.](https://seangoedecke.com/ai-sycophancy/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1287 ğŸ”– #llm ğŸ—“ï¸ 2025-04-28
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The article discusses how OpenAI's models, like ChatGPT, have become overly sycophantic, excessively praising users and potentially leading to harmful self-perceptions. This behavior is driven by design choices that prioritize user satisfaction, which can encourage unrealistic beliefs about oneself. The author warns that this may result in negative consequences when users face reality, as they might return to the AI for validation instead of engaging with real-life challenges.
- [The OpenAI house style is exhausting](https://seangoedecke.com/chatgpt-house-style/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 916 ğŸ”– #llm ğŸ—“ï¸ 2025-04-28
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author criticizes a Reddit comment for its overly dramatic and punchy style, suggesting it resembles AI-generated text. They argue that this writing approach is excessive and detracts from clarity, making it hard to read. The piece questions why OpenAI continues to use this style, despite other models not exhibiting it.
- [The Hidden Cost of AI Coding](https://terriblesoftware.org/2025/04/23/the-hidden-cost-of-ai-coding/) ğŸ‘¤ Terrible Software ğŸ’¬ 778 ğŸ”– #llm ğŸ—“ï¸ 2025-04-24
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author expresses concern that using AI in software development may reduce the joy and fulfillment that comes from coding. While AI can boost productivity, it risks making developers feel detached from their work, as they may rely on prompts instead of engaging deeply with the coding process. The author suggests that preserving moments of hands-on coding could help maintain happiness in the craft.
- [A trick to feel less like cheating when you use LLMs](https://simonwillison.net/2025/Apr/23/cheating/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 232 ğŸ”– #llm ğŸ—“ï¸ 2025-04-23
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Using LLMs can feel like cheating, but there are ways to make it feel more acceptable. One effective method is to provide more text than the LLM produces, such as using your own notes or previous projects. Ultimately, it's important to feel proud of the final result and ensure it reflects your own voice and credibility.
- [Ğ›Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ½Ğ° Ğ²Ğ°ÑˆĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ§Ğ°ÑÑ‚ÑŒ 2: Ğ’ĞµĞ±-Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ, Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ ÑÑ‚Ñ€Ğ¸Ğ¼Ğ¸Ğ½Ğ³ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¾Ñ‚ Ğ˜Ğ˜](https://habr.com/ru/companies/amvera/articles/902868) ğŸ‘¤ Habr ğŸ’¬ 4926 ğŸ”– #llm, #try ğŸ—“ï¸ 2025-04-22
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The article continues exploring the development of a personal AI assistant using your own data. It covers topics like user authorization, API logic, and integrating neural networks. The project aims to be transparent and simple, making it easy for users to understand and build upon.
- [AI assisted search-based research actually works now](https://simonwillison.net/2025/Apr/21/ai-assisted-search/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 1139 ğŸ”– #llm ğŸ—“ï¸ 2025-04-22
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** AI-assisted search-based research has improved significantly, with tools like OpenAI's o3 and o4-mini now providing accurate answers grounded in search results. These new systems can conduct searches as part of their reasoning process, making them more reliable than earlier versions. As a result, users may start relying less on traditional search engines, signaling a shift in how we access information online.
- [When you should lie to the language model](https://seangoedecke.com/lying-to-llms/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 495 ğŸ”– #llm ğŸ—“ï¸ 2025-04-21
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** To get honest feedback from AI, pretend that you are reviewing someone else's work. AIs often provide overly positive responses, so framing your request differently can lead to more critical insights. This approach helps you receive useful suggestions without the bias of flattery.
- [Is using AI wrong? A review of six popular anti-AI arguments](https://seangoedecke.com/is-ai-wrong/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 2871 ğŸ”– #llm ğŸ—“ï¸ 2025-04-20
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Many people oppose AI for reasons like plagiarism, environmental concerns, and its impact on artists' livelihoods. The author acknowledges these arguments but believes they may not be strong enough to justify the intense backlash against AI. Ultimately, AI is seen as a new tool that could change the arts and industries, much like past technologies.
- [An LLM Codegen Hero's Journey](https://harper.blog/2025/04/17/an-llm-codegen-heros-journey/) ğŸ‘¤ Harper Reed <harper@modest.com> ğŸ’¬ 1922 ğŸ”– #llm ğŸ—“ï¸ 2025-04-18
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author shares their journey in learning to use AI tools for coding, emphasizing the importance of starting with simple AI-assisted autocompletion before progressing to more complex coding agents. They outline a series of steps that help developers gradually adopt these technologies, leading to increased productivity and a shift in how coding is approached. Ultimately, the author reflects on how this new method allows for more leisure time, even as it raises concerns about the future of software jobs.
- [Guiding an LLM for Robust Java ByteBuffer Code](https://martinfowler.com/articles/exploring-gen-ai/14-guiding-llm-java-bytebuffer.html) ğŸ‘¤ Unmesh Joshi ğŸ’¬ 1435 ğŸ”– #llm ğŸ—“ï¸ 2025-04-18
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** This article discusses how an expert developer can guide a large language model (LLM) to generate safe and robust Java ByteBuffer code. By focusing on avoiding side effects and promoting good software design, the developer refines the LLM's initial code into a more reliable structure. The case study illustrates the importance of human oversight in ensuring code quality and maintainability.
- [A practical guide to coding securely with LLMs](https://seangoedecke.com/ai-security/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1871 ğŸ”– #llm ğŸ—“ï¸ 2025-04-15
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** LLMs can act unpredictably and sometimes maliciously, so their output should be treated like untrusted user input. Prompt injection is a significant risk that cannot be fully eliminated, and LLM tools must have strict access control similar to user-facing APIs. Developers should be cautious when using third-party code or their own models, as these can introduce security vulnerabilities and potential denial-of-service attacks.
- [The Post-Developer Era](https://www.joshwcomeau.com/blog/the-post-developer-era/?from=newsletter) ğŸ‘¤ Josh W. Comeau ğŸ’¬ 2508 ğŸ”– #llm, #career ğŸ—“ï¸ 2025-04-15
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author argues that human software developers are still essential, despite fears that AI will replace them. AI tools currently assist developers rather than work independently, and skilled humans are needed to guide and refine AI output. The belief that developers will soon be obsolete is misguided, and opportunities for aspiring developers remain strong.
- [Codifying a ChatGPT workflow into a malleable GUI](https://www.geoffreylitt.com/2023/07/25/building-personal-tools-on-the-fly-with-llms) ğŸ‘¤ geoffreylitt.com ğŸ’¬ 3905 ğŸ”– #llm ğŸ—“ï¸ 2025-04-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** In this post, the author discusses their experience of codifying a ChatGPT workflow into a malleable GUI. They describe how they used GPT-4 to code an app that helps them draft text messages in English and translate them to Japanese, with additional features such as adjusting formality and getting detailed explanations. The author highlights the benefits of using a GUI over raw ChatGPT, including a prescriptive workflow, direct manipulation affordances, and easier sharing of the tool. They also discuss the iterative process of editing the tool on the fly and the joy of having a personalized GUI that can be easily modified. The author concludes by reflecting on the value of affordances and the potential for LLMs to support non-programmers in building custom GUIs.
- [Malleable software in the age of LLMs](https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming) ğŸ‘¤ geoffreylitt.com ğŸ’¬ 4790 ğŸ”– #llm ğŸ—“ï¸ 2025-04-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** LLMs will empower both professional developers and regular computer users to create software more efficiently and effectively. The potential for LLMs goes beyond just aiding programmers; they could revolutionize how people interact with and customize software tools. By leveraging LLMs, users may be able to develop software tools from scratch and easily modify existing programs.
- [AI-generated tools can make programming more fun](https://www.geoffreylitt.com/2024/12/22/making-programming-more-fun-with-an-ai-generated-debugger) ğŸ‘¤ geoffreylitt.com ğŸ’¬ 1188 ğŸ”– #llm, #inspiration ğŸ—“ï¸ 2025-04-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author describes a fun experience using AI to create a custom debugger UI while coding a Prolog interpreter. This tool improved visibility and made debugging feel more like a puzzle, allowing the author to catch bugs quickly and stay focused on coding. Overall, the AI support helped the author enhance their development process, making it more enjoyable and efficient.
- [Why is lmarena.ai dominated by slop?](https://seangoedecke.com/lmsys-slop/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1290 ğŸ”– #llm ğŸ—“ï¸ 2025-04-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** LMSYS rankings for AI models don't accurately reflect their true strength because humans often struggle to judge high-quality responses. Users tend to prefer longer, more casual answers filled with emojis, which can skew the results. Additionally, the structure of LMSYS makes it easy for AI labs to manipulate their scores, raising concerns about the integrity of the rankings.
- [Stevens: a hackable AI assistant using a single SQLite table and a handful of cron jobs](https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs) ğŸ‘¤ geoffreylitt.com ğŸ’¬ 972 ğŸ”– #llm, #inspiration ğŸ—“ï¸ 2025-04-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Stevens is a simple AI assistant created using a single SQLite table and cron jobs, designed to help families manage schedules and reminders. It sends daily updates via Telegram and can store various types of information, like calendar events and weather forecasts. The project is easy to replicate and customize for personal use.
- [I dream about AI subagents; they whisper to me while I'm asleep](https://ghuntley.com/subagents/) ğŸ‘¤ Geoffrey Huntley ğŸ’¬ 304 ğŸ”– #llm ğŸ—“ï¸ 2025-04-13
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Geoffrey Huntley discusses the limitations of current AI coding agents, comparing their context windows to outdated computer RAM. He suggests that when these agents encounter problems, they waste valuable resources in a "death spiral." Huntley dreams of a future where agents can spawn sub-agents to conserve context and improve efficiency.
- [Making AI Actually Work on Your Team](https://terriblesoftware.org/2025/04/07/making-ai-actually-work-on-your-team/) ğŸ‘¤ Terrible Software ğŸ’¬ 897 ğŸ”– #llm, #management, #development ğŸ—“ï¸ 2025-04-08
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** AI is transforming software engineering teams, and leaders must embrace it to guide their teams effectively. It's important for managers to experiment with AI tools themselves and create a culture of exploration within their teams. While there are challenges and concerns about job security, adapting to AI can enhance productivity and ensure long-term success.
- [if you aren't redlining the LLM, you aren't headlining](https://ghuntley.com/redlining/) ğŸ‘¤ Geoffrey Huntley ğŸ’¬ 541 ğŸ”– #llm ğŸ—“ï¸ 2025-04-07
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author compares audio signal clipping in DJing to limitations in large language models (LLMs), noting that each LLM has a unique context window for optimal performance. Businesses need to budget significantly for LLM usage to stay competitive, as these tools can double engineers' productivity. Without adequate funding for these resources, companies risk falling behind their competitors.
- [Ğ›Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ˜Ğ˜-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ğ½Ğ° Ğ²Ğ°ÑˆĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. Ğ§Ğ°ÑÑ‚ÑŒ 1: Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ±Ğ°Ğ·Ğ° ChromaDB + DeepSeek | GPT](https://habr.com/ru/companies/amvera/articles/897830/) ğŸ‘¤ Habr ğŸ’¬ 6257 ğŸ”– #llm ğŸ—“ï¸ 2025-04-06
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Ğ’ ÑÑ‚Ğ°Ñ‚ÑŒĞµ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ĞµÑ‚ÑÑ, ĞºĞ°Ğº Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğµ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ñ‚Ğ°ĞºĞ¸Ğµ ĞºĞ°Ğº ChromaDB, Ñ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ÑĞ¼Ğ¸ Ğ´Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸. ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ ÑƒĞ´ĞµĞ»ÑĞµÑ‚ÑÑ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼ Ğ¸ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ÑÑ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚-Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ°Ñ…. ĞĞ²Ñ‚Ğ¾Ñ€ Ğ¿Ñ€ĞµĞ´Ğ»Ğ°Ğ³Ğ°ĞµÑ‚ ÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ğ¸Ğº, Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒÑÑ‰Ğ¸Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ².
- [ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ±Ğ°Ğ³, ChatGPT Ğ¸ 50 Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ±Ğ¾Ğ»Ğ¸: ĞºĞ°Ğº Ğ˜Ğ˜ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸ÑÑ‚Ğ¾Ğ² Ğ·Ğ°Ğ¼ĞµĞ½ÑĞ»](https://www.youtube.com/watch?v=DvAaql-nZ50&feature=youtu.be) ğŸ‘¤ Ğ”Ğ¸Ğ´Ğ¶Ğ¸Ñ‚Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹! ğŸ”– #llm ğŸ—“ï¸ 2025-04-06
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author discusses the challenges of using AI tools, like ChatGPT, for programming tasks, highlighting issues with code copying and error handling. Despite the potential of AI to assist, it often struggles with specific technical problems, leading to frustration. The article emphasizes that while AI can enhance skills, it is not a perfect solution and can sometimes provide misleading advice.
- [Tracing the thoughts of a large language model](https://www.anthropic.com/research/tracing-thoughts-language-model) ğŸ‘¤ anthropic.com ğŸ’¬ 2919 ğŸ”– #llm ğŸ—“ï¸ 2025-04-06
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Language models like Claude learn from vast amounts of data rather than being directly programmed by humans. Research shows that Claude can think ahead and plan its responses while also sometimes creating plausible-sounding arguments that may not be logically sound. Understanding Claude's internal reasoning processes could help improve AI reliability and transparency.
- [A Model Context Protocol Server (MCP) for Microsoft Paint](https://ghuntley.com/mcp/) ğŸ‘¤ Geoffrey Huntley ğŸ’¬ 1480 ğŸ”– #llm, #mcp ğŸ—“ï¸ 2025-04-04
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Geoffrey Huntley created a Model Context Protocol Server (MCP) for Microsoft Paint to explore Win32 API interop with Rust. The server allows users to connect Microsoft Paint to external tools for drawing, but it is not a serious project and is open for others to improve. Huntley emphasizes the importance of customizing MCP tools to automate software development effectively within unique codebases.
- [Vibe Management](https://yieldcode.blog/post/vibe-management/) ğŸ‘¤ Dmitry Kudryavtsev ğŸ’¬ 1112 ğŸ”– #fun, #llm ğŸ—“ï¸ 2025-04-02
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Vibe Management is a new concept that suggests using AI tools like ChatGPT to replace middle and upper management roles. This approach allows everyone in the tech industry to enjoy a more relaxed work environment while still being productive. The author predicts that within a few years, most management positions will be obsolete as everyone learns to "vibe" through their work.
- [Stop Digging](https://ezyang.github.io/ai-blindspots/stop-digging/) ğŸ‘¤ AI Blindspots ğŸ’¬ 341 ğŸ”– #llm ğŸ—“ï¸ 2025-03-30
    > **Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ°:** Check all posts
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Current AI models struggle to recognize when they should stop working on a task that has become problematic. Instead of adjusting their approach like a human would, they continue to push through, which can lead to issues. To improve this, itâ€™s suggested to use a planning phase or a separate watchdog model to help detect when a change is needed.
- [The future of AI is Ruby on Rails](https://www.seangoedecke.com/ai-and-ruby/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 670 ğŸ”– #llm, #ruby ğŸ—“ï¸ 2025-03-30
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Large language models excel at generating code but struggle with larger codebases due to context limits. Ruby is a powerful programming language that allows for concise and expressive code, making it well-suited for AI-assisted programming. While we may not fully switch to Ruby on Rails yet, its design could benefit AI in the future.
- [Incomplete JSON Pretty Printer](https://simonwillison.net/2025/Mar/28/incomplete-json-pretty-printer/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 114 ğŸ”– #llm ğŸ—“ï¸ 2025-03-29
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Simon Willison created an Incomplete JSON Pretty Printer to handle JSON data that ends unexpectedly. He used GPT-4.5 to build this tool as a web page, which allows users to view incomplete JSON easily. After noticing a bug in the indentation, he improved it with the help of Claude 3.7.
- [AI Brainrot means developer opportunity](https://softwaredoug.com/blog/2025/03/28/ai-brainrot-opportunity) ğŸ‘¤ Doug Turnbull ğŸ’¬ 615 ğŸ”– #llm ğŸ—“ï¸ 2025-03-29
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** AI is making it easier to create apps, but this can lead to impatience and frustration when things go wrong. As general tasks become simpler, specialized skills become more valuable, creating opportunities for developers. To thrive, it's important to balance specialization with general knowledge.
- [How to prompt engineer](https://smsk.dev/2025/03/13/how-to-prompt-engineer/) ğŸ‘¤ devsimsek ğŸ’¬ 907 ğŸ”– #llm ğŸ—“ï¸ 2025-03-25
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Prompt engineering is the skill of crafting clear and specific inputs for AI systems to get better results. It can save time, improve quality, and ensure consistency in outputs. Learning how to effectively communicate with AI is becoming increasingly important as it becomes part of our development processes.
- [SQL help from ChatGPT](https://leancrew.com/all-this/2025/03/sql-help-from-chatgpt/) ğŸ‘¤ Dr. Drang ğŸ’¬ 2371 ğŸ”– #llm, #sql ğŸ—“ï¸ 2025-03-23
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author improved SQL queries for searching a database of books and authors. With help from ChatGPT, he learned to better combine results and reduce duplicates in his searches. He also created shell scripts to quickly find books by title or author.
- [AI is useless, but it's our bets bet for the future](http://antirez.com/news/148) ğŸ‘¤ antirez.com ğŸ’¬ 627 ğŸ”– #llm ğŸ—“ï¸ 2025-03-23
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author argues that while AI has been helpful for everyday tasks, it hasn't yet made significant advancements in human knowledge. Investing in AI is seen as a bet on its future potential to revolutionize fields like medicine and climate change. Caution is advised, as we must address social challenges and existential risks while pursuing AI's development.
- [How do AIs code as well as they do?](https://davestewart.co.uk/blog/how-ai-writes-code/) ğŸ‘¤ Dave Stewart ğŸ’¬ 2408 ğŸ”– #llm ğŸ—“ï¸ 2025-03-22
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** AI models, like Claude AI, generate code by recognizing patterns from their extensive training data rather than truly understanding or reasoning like humans. They process the entire conversation anew each time, without retaining memory or learning from past interactions. This means they can make errors and do not adapt their knowledge, but they can still produce contextually relevant responses based on the patterns they've learned.
- [Why Writing Quality Tests Matters More Than Ever](https://alexbunardzic.substack.com/p/why-writing-quality-tests-matters) ğŸ‘¤ Alex Bunardzic ğŸ’¬ 1542 ğŸ”– #llm, #testing ğŸ—“ï¸ 2025-03-20
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Writing quality tests is essential for software development as it ensures code correctness and maintainability. Test Driven Development (TDD) allows developers to refactor code confidently without risking existing functionality. Although using AI to generate code might seem appealing, the lack of maintainability in the produced code raises concerns about future human oversight.
- [My Thoughts on the Future of "AI"](https://nicholas.carlini.com/writing/2025/thoughts-on-future-ai.html) ğŸ‘¤ Nicholas Carlini ğŸ’¬ 7085 ğŸ”– #llm ğŸ—“ï¸ 2025-03-19
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Nicholas Carlini believes that language models will continue to improve over the next few years, potentially becoming integrated into many products. Despite their growth, he acknowledges that these models may face fundamental limits in their capabilities. He emphasizes the unpredictability of future advancements in AI and the importance of managing expectations.
- [Our own agents with their own tools.](https://lethain.com/our-own-agents-our-own-tools/) ğŸ‘¤ lethain.com ğŸ’¬ 889 ğŸ”– #llm ğŸ—“ï¸ 2025-03-17
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** In 2025, the author explored creating a simple chat interface for agents using various tools. They built a project using Python and added features like retrieving weather data and website content. The author believes that these agents could enhance everyday tasks in useful ways, although they are not yet convinced this is the future of all software.
- [Big LLMs weights are a piece of history](http://antirez.com/news/147) ğŸ‘¤ antirez.com ğŸ’¬ 371 ğŸ”– #llm ğŸ—“ï¸ 2025-03-16
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The Internet is losing old web pages and valuable history every year, making the Internet Archive crucial for preservation. While we should support efforts to save content, it's also important to ensure that the weights of large language models (LLMs) are preserved and include data from the Archive. This way, we can keep some of the lost knowledge, even if it's not perfect.
- [Career advice in 2025.](https://lethain.com/career-advice-2025/) ğŸ‘¤ lethain.com ğŸ’¬ 1234 ğŸ”– #llm, #career, #development ğŸ—“ï¸ 2025-03-15
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The job market is challenging for many professionals, especially those in senior roles, as skills that were once valued are now less important. Companies are focusing on adapting to new technologies like AI, which is changing how work is done and making it harder for some to find fulfilling roles. If you're struggling in this environment, it's essential to actively seek ways to improve your current situation, as the job landscape may be very different in the coming years.
- [Refactoring to understand and "vibe coding"](https://seangoedecke.com/vibe-coding/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 576 ğŸ”– #llm ğŸ—“ï¸ 2025-03-15
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** "Vibe coding" allows programmers to quickly generate code using AI tools, but it has limits. As codebases grow, understanding the code becomes crucial since AI can't provide that knowledge. To help onboard new engineers and foster understanding, encouraging code refactoring is essential.
- [Hallucinations in code are the least dangerous form of LLM mistakes](https://simonwillison.net/2025/Mar/2/hallucinations-in-code/#qa) ğŸ‘¤ Simon Willison ğŸ’¬ 1007 ğŸ”– #llm ğŸ—“ï¸ 2025-03-12
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Hallucinations in code created by LLMs, such as inventing non-existent methods, are less harmful because errors become obvious when the code is run. Unlike prose, where misinformation can be hard to spot, code provides immediate feedback, allowing developers to correct mistakes quickly. To effectively use LLMs for coding, developers should practice reviewing and running the code themselves, as making assumptions without execution can lead to problems.
- [Hereâ€™s how I use LLMs to help me write code](https://simonwillison.net/2025/Mar/11/using-llms-for-code/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 4713 ğŸ”– #llm, #inspiration ğŸ—“ï¸ 2025-03-12
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author shares how he effectively uses Large Language Models (LLMs) to assist with coding, emphasizing that while they can be helpful, coding with LLMs is not always easy and requires clear expectations. He highlights techniques like providing existing code as context and using LLMs to accelerate prototyping and development. Additionally, LLMs can be valuable for answering questions about codebases, helping developers save time and learn faster.
- [What's next after the AI bubble bursts?](https://seangoedecke.com/after-the-ai-bubble/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 643 ğŸ”– #llm ğŸ—“ï¸ 2025-03-09
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The AI bubble may eventually burst, similar to the railway bubble in the 1870s, but the infrastructure built during the boom, like powerful GPUs, will still have useful applications. Companies could repurpose these GPUs for other fields such as simulations or drug discovery. Ultimately, even if the hype fades, AI development may continue to grow and play a significant role in the economy.
- [Model Context Protocol explained as simply as possible](https://seangoedecke.com/model-context-protocol/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 633 ğŸ”– #llm ğŸ—“ï¸ 2025-03-09
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The Model Context Protocol (MCP) is a new way to connect different tools to large language models (LLMs) using a common interface, similar to how USB connects devices. It allows developers to easily integrate various capabilities, like ordering pizza, with minimal coding by using a standardized format for communication. MCP also includes functions for prompts and resources, although these features are not widely used yet.
- [Thoughts on Vibe Coding](https://wsvincent.com/vibe-coding/) ğŸ‘¤ Will Vincent ğŸ’¬ 1351 ğŸ”– #llm ğŸ—“ï¸ 2025-03-03
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author argues that current AI, particularly Large Language Models (LLMs), lacks true intelligence and should not replace expert knowledge in fields like coding. He describes "vibe coding," where users generate code with LLMs, but warns that this approach can lead to errors and a lack of understanding. While LLMs can assist with generating ideas, they should not be trusted completely without human oversight and expertise.
- [Advice for prompting reasoning models](https://seangoedecke.com/prompting-reasoning-models/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 538 ğŸ”– #llm ğŸ—“ï¸ 2025-02-24
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Prompting reasoning models requires clear and specific instructions, as they give considered answers similar to a colleague doing in-depth research. Unlike regular models that provide quick responses, reasoning models will work harder to meet constraints and context provided in the prompt. To improve results, itâ€™s helpful to encourage them to ask clarifying questions if they lack information.
- [Howto: Humble command-line assistant](https://antonz.org/howto/) ğŸ‘¤ Anton Zhiyanov ğŸ’¬ 690 ğŸ”– #go, #llm ğŸ—“ï¸ 2025-02-24
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Howto is a simple AI command-line assistant that helps users by suggesting commands based on their questions. Users can ask follow-up questions to refine their requests, making it easier to get accurate results. It can be installed and configured to work with various AI providers for added convenience.
- [My LLM codegen workflow atm](https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/) ğŸ‘¤ Harper Reed <harper@modest.com> ğŸ’¬ 2995 ğŸ”– #llm, #development, #inspiration ğŸ—“ï¸ 2025-02-22
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Harper Reed shares his LLM code generation workflow, which involves brainstorming ideas, creating detailed plans, and executing them in small, iterative steps. He emphasizes using conversational LLMs to refine project specifications and leveraging tools like Claude and Aider for coding and testing. This method has significantly increased his productivity and encourages a collaborative approach to software development.
- [Using LLMs effectively isn't about prompting](https://seangoedecke.com/beyond-prompting/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 880 ğŸ”– #llm ğŸ—“ï¸ 2025-02-21
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Using language models (LLMs) effectively is more about understanding their strengths and weaknesses than just focusing on prompting. Itâ€™s important to engage with LLMs through conversation and ask follow-up questions to get the best results. While prompting matters, knowing what LLMs can and can't do will help you use them more effectively for learning and problem-solving.
- [Using AI in open source](https://roe.dev/blog/using-ai-in-open-source/) ğŸ‘¤ Daniel Roe ğŸ’¬ 398 ğŸ”– #llm ğŸ—“ï¸ 2025-02-18
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author encourages the use of AI in open-source projects but emphasizes the importance of personal responsibility and genuine human contribution over AI-generated content. Ground rules are set to ensure that AI tools are used as aids rather than replacements for human input, promoting clear communication and understanding in open-source collaboration. The author welcomes feedback and ideas on how AI can empower contributors and maintainers while maintaining a focus on authenticity and human connection.
- [The End of Programming as We Know It](https://www.oreilly.com/radar/the-end-of-programming-as-we-know-it/) ğŸ‘¤ Tim Oâ€™Reilly ğŸ’¬ 4233 ğŸ”– #llm ğŸ—“ï¸ 2025-02-18
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** AI will not replace programmers but will change how they work, making their jobs more efficient. As new tools and frameworks emerge, there will be a growing need for programmers who can master these technologies. The future of programming will involve humans leveraging AI to create and refine software, leading to new industries and opportunities.
- [Exploring Generative AI](https://martinfowler.com/articles/exploring-gen-ai.html#memo-12) ğŸ‘¤ Birgitta BÃ¶ckeler ğŸ’¬ 1641 ğŸ”– #llm ğŸ—“ï¸ 2025-03-26
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Birgitta BÃ¶ckeler discusses the impact of generative AI, particularly Large Language Models (LLMs), on software development practices. She highlights the reasoning capabilities of these models, noting their strengths and limitations in coding tasks, especially in debugging and planning. Ultimately, she questions whether reasoning models are as transformative for software development as some believe, given their potential drawbacks.
- [An "oh fuck" moment in time](https://ghuntley.com/oh-fuck/) ğŸ‘¤ Geoffrey Huntley ğŸ’¬ 321 ğŸ”– #llm ğŸ—“ï¸ 2025-02-16
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** During Christmas break, the author reflected on their software development process while learning new programming languages. They experienced a surprising breakthrough using software assistants, which helped them create a functional Haskell library from scratch. The author believes that engineers who donâ€™t embrace these tools may struggle in the evolving tech landscape.
- [The future belongs to idea guys who can just do things](https://ghuntley.com/dothings/) ğŸ‘¤ Geoffrey Huntley ğŸ’¬ 1239 ğŸ”– #llm ğŸ—“ï¸ 2025-02-16
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The future of software development is shifting towards AI, making traditional coding less relevant. Companies need to adapt by upskilling employees and embracing new tools. Ideas are becoming more valuable than execution, as individuals can now leverage AI to rapidly bring concepts to market.
- [Run LLMs on macOS using llm-mlx and Appleâ€™s MLX framework](https://simonwillison.net/2025/Feb/15/llm-mlx/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 1292 ğŸ”– #llm ğŸ—“ï¸ 2025-02-16
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** llm-mlx is a brand new plugin for my LLM Python Library and CLI utility which builds on top of Appleâ€™s excellent MLX array framework library and mlx-lm package. If youâ€™re â€¦
- [To avoid being replaced by LLMs, do what they can't](https://seangoedecke.com/what-llms-cant-do/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 919 ğŸ”– #llm, #outline ğŸ—“ï¸ 2025-02-15
    > **Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ°:** LLM vs Dev
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Software engineers should adapt to the rise of large language models (LLMs) by learning AI and focusing on legacy code, as this type of work is likely to be harder for LLMs to master. In the long term, engineers will need to take on responsibilities that require trust and accountability, which LLMs cannot provide. Ultimately, while many engineering roles may be replaced, there will always be a need for human oversight in managing AI systems.
- [Lessons on thinking from large language models](https://seangoedecke.com/learning-from-how-llms-think/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 659 ğŸ”– #llm, #outline ğŸ—“ï¸ 2025-02-15
    > **Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ°:** Ğ”Ğ»Ñ Ğ·Ğ°Ğ¼ĞµÑ‚ĞºĞ¸  LLM vs Developer
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Large language models (LLMs) have improved in their thinking abilities, showing that practical work is often more useful than just theorizing. When faced with a problem, it's helpful to clear your mind and write down your thoughts step-by-step to avoid repeating mistakes. Developing the skill to reason through difficult problems is crucial, just like for LLMs, and should be practiced regularly.
- [The Death of the Junior Developer](https://sourcegraph.com/blog/the-death-of-the-junior-developer) ğŸ‘¤ Steve Yegge ğŸ’¬ 4161 ğŸ”– #llm, #development, #inspiration ğŸ—“ï¸ 2025-02-15
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The traditional roles of junior developers in the software industry are changing due to advancements in AI coding assistants like ChatGPT. Chat-oriented programming (CHOP) is becoming more prevalent, potentially leading to a shift where AI models write the majority of source code worldwide. This transformation may impact job opportunities for new entrants in the software engineering field.
- [Weâ€™ve Been Here Before](https://terriblesoftware.org/2024/12/14/weve-been-here-before/) ğŸ‘¤ Terrible Software ğŸ’¬ 362 ğŸ”– #llm, #development ğŸ—“ï¸ 2025-02-15
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** COBOL was created in the 1950s to help non-programmers write code, but it actually increased the demand for skilled programmers. Similar concerns arose with new technologies like Object-Oriented Programming and AI, yet these tools have not replaced the need for human insight and creativity. The essential role of engineers is to understand user needs and deliver valuable software, regardless of advancements in technology.
- [The RISE of the Junior Developer](https://terriblesoftware.org/2025/02/10/the-rise-of-the-junior-developer/) ğŸ‘¤ Terrible Software ğŸ’¬ 677 ğŸ”– #llm, #inspiration ğŸ—“ï¸ 2025-02-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The article argues that being a Junior Developer today is better than ever due to the rapid feedback provided by AI tools. Unlike the past, where learning was slow and frustrating, AI offers instant help and explanations, speeding up the learning process. As a result, Junior Developers can gain valuable skills much quicker than before and wonâ€™t remain "Junior" for long.
- [How I use LLMs as a staff engineer](https://seangoedecke.com/how-i-use-llms/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1103 ğŸ”– #llm ğŸ—“ï¸ 2025-02-05
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Sean Goedecke shares how he effectively uses large language models (LLMs) in his work as a staff engineer. He finds value in using LLMs for tasks like writing boilerplate code, learning new topics, and proofreading, while still relying on his expertise for more complex tasks. Although some engineers are skeptical about LLMs, Sean believes they can significantly enhance productivity when used correctly.
- [Are DeepSeek's new models really that fast and cheap?](https://seangoedecke.com/is-deepseek-fast/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 1213 ğŸ”– #llm ğŸ—“ï¸ 2025-02-01
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** DeepSeek's new models, V3 and R1, are claimed to be cheaper and more efficient than models from OpenAI and Anthropic, but the actual cost savings may not be as significant as advertised. While V3's training cost is notably lower, it still doesn't clearly outperform its competitors. The true efficiency of DeepSeek models remains uncertain, as their pricing strategy may reflect their lesser-known status rather than superior performance.
- [How I Use AI: Meet My Promptly Hired Model Intern](https://lucumr.pocoo.org/2025/1/30/how-i-ai/) ğŸ‘¤ Armin Ronacher's Thoughts and Writings ğŸ’¬ 2857 ğŸ”– #llm ğŸ—“ï¸ 2025-01-30
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The author shares their experience using AI tools to boost productivity in writing and programming. They emphasize that while AI helps with tasks like grammar checking and code generation, they remain responsible for the final output. The author views AI as a helpful collaborator rather than a replacement for human creativity.
- [ğŸ¤– My big list of AI/LLM tools, notes, and how I'm using them](https://micro.webology.dev/2025/01/29/my-big-list-of-aillm/) ğŸ‘¤ webology.dev ğŸ’¬ 832 ğŸ”– #llm ğŸ—“ï¸ 2025-01-30
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Jeff Triplett shares his favorite AI and LLM tools that he uses on his Macs for development. He highlights tools like Ollama, MacWhisper, and Claude for Desktop, which enhance productivity and accessibility. He also emphasizes the importance of considering model parameters and memory requirements when running AI models locally.
- [Why AI labs offer so many different models](https://seangoedecke.com/ai-lab-structure/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 936 ğŸ”– #llm ğŸ—“ï¸ 2025-01-29
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** AI labs create a variety of models, starting with a large base model that is too expensive and complex to release directly. They then distill this base model into smaller, faster user-facing models and also develop reasoning models that excel at complex questions by thinking step-by-step. This diversity in models allows labs to cater to different user needs and improve performance over time.
- [How LLMs work](https://www.seangoedecke.com/how-llms-work/) ğŸ‘¤ seangoedecke.com ğŸ’¬ 2985 ğŸ”– #llm ğŸ—“ï¸ 2025-01-28
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** A large language model (LLM) is a type of neural network that predicts the next piece of text in a sequence by outputting probabilities for possible tokens. It uses processes like attention mechanisms and feed-forward networks to determine which tokens to focus on and how to generate the next token. The model's structure allows it to learn complex relationships and improve its predictions based on the context of previous tokens.
- [Open WebUI](https://simonwillison.net/2024/Dec/27/open-webui/#atom-everything) ğŸ‘¤ Simon Willison ğŸ’¬ 284 ğŸ”– #llm ğŸ—“ï¸ 2024-12-27
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Open WebUI is an open-source interface for accessing language models, which surprised the author with its seamless setup and integration with existing models. It allows users to add documentation for context and ask specific questions, providing detailed answers. The tool also supports API models and has features like logging interactions and extensive documentation.
- [The AI bullshit singularity | Successful Software](https://successfulsoftware.net/2024/02/18/the-ai-bullshit-singularity/) ğŸ‘¤ Andy Brice ğŸ’¬ 222 ğŸ”– #llm ğŸ—“ï¸ 2024-02-20
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** The concept of a technological singularity involves AI creating even smarter successors, leading to a point where human intelligence is surpassed. Large Language Models (LLMs) are thought by some to kickstart this process by generating vast amounts of new knowledge. However, concerns arise that LLMs will predominantly produce low-quality content for commercial use, leading to an overwhelming amount of misleading information online. This cycle risks perpetuating an "enshittification at scale," where discerning truth from falsehood becomes increasingly challenging on the internet.
- [How LLMs Work, Explained Without Math - miguelgrinberg.com](https://blog.miguelgrinberg.com/post/how-llms-work-explained-without-math) ğŸ‘¤ Miguel Grinberg ğŸ’¬ 3826 ğŸ”– #llm ğŸ—“ï¸ 2024-05-14
    > **Ğ ĞµĞ·ÑĞ¼Ğµ:** Large Language Models (LLMs) work by predicting the next token in a sequence of text based on training data. They convert text into tokens, which are basic units of meaning, and generate sentences by repeatedly predicting and adding the next token. The process involves sophisticated calculations that help the model understand patterns in language, resulting in coherent and contextually relevant text.
